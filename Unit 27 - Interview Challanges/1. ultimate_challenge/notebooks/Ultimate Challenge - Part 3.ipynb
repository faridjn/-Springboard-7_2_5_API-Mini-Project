{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "877a6085",
   "metadata": {},
   "source": [
    "# Data Analysis Interview Challenge\n",
    "\n",
    "## Part 3 ‐ Predictive modeling\n",
    "\n",
    "Ultimate Technologies Inc. is a transportation network company that has disrupted the taxi and logistics industry and is considered a prestigious company to work for. This challenge has been adapted from an actual Ultimate Inc. data science challenge.\n",
    "\n",
    "\n",
    "Ultimate is interested in predicting rider retention. To help explore this question, we have provided a sample dataset of a cohort of users who signed up for an Ultimate account in January 2014. The data was pulled several months later; we consider a user retained if they were “active” (i.e. took a trip) in the preceding 30 days.\n",
    "\n",
    "We would like you to use this data set to help understand what factors are the best predictors for retention, and offer suggestions to operationalize those insights to help Ultimate.\n",
    "\n",
    "The data is in the attached file `ultimate_data_challenge.json`. See below for a detailed description of the dataset. Please include any code you wrote for the analysis and delete the dataset when you have finished with the challenge.\n",
    "\n",
    "1. Perform any cleaning, exploratory analysis, and/or visualizations to use the provided data for this analysis (a few sentences/plots describing your approach will suffice). What fraction of the observed users were retained?\n",
    "2. Build a predictive model to help Ultimate determine whether or not a user will be active in their 6th month on the system. Discuss why you chose your approach, what alternatives you considered, and any concerns you have. How valid is your model? Include any key indicators of model performance.\n",
    "3. Briefly discuss how Ultimate might leverage the insights gained from the model to improve its long term rider retention (again, a few sentences will suffice).\n",
    "\n",
    "\n",
    "### Data description\n",
    "\n",
    "- `city`: city this user signed up in\n",
    "- `phone`: primary device for this user\n",
    "- `signup_date`: date of account registration; in the form ‘YYYYMMDD’\n",
    "- `last_trip_date`: the last time this user completed a trip; in the form ‘YYYYMMDD’\n",
    "- `avg_dist`: the average distance in miles per trip taken in the first 30 days after signup\n",
    "- `avg_rating_by_driver`: the rider’s average rating over all of their trips\n",
    "- `avg_rating_of_driver`: the rider’s average rating of their drivers over all of their trips\n",
    "- `surge_pct`: the percent of trips taken with surge multiplier > 1\n",
    "- `avg_surge`: The average surge multiplier over all of this user’s trips\n",
    "- `trips_in_first_30_days`: the number of trips this user took in the first 30 days after signing up\n",
    "- `ultimate_black_user`: TRUE if the user took an Ultimate Black in their first 30 days; FALSE otherwise\n",
    "- `weekday_pct`: the percent of the user’s trips occurring during a weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88985f16",
   "metadata": {},
   "source": [
    "## 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da018b1",
   "metadata": {},
   "source": [
    "The problem statement is to help Ultimate Technologies Inc., a transportation network company, predict rider retention by analyzing a provided dataset of users who signed up for an Ultimate account in January 2014. The objective is to identify the factors that are the best predictors for rider retention and provide suggestions for operationalizing those insights to help Ultimate. The challenge requires performing data cleaning, exploratory analysis, and building a predictive model to determine if a user will be active in their 6th month on the system. The solution should include a discussion of the chosen approach, alternatives considered, and key indicators of model performance. Finally, the challenge requires a brief discussion on how Ultimate can leverage the insights gained from the model to improve its long-term rider retention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2e1f21",
   "metadata": {},
   "source": [
    "## 2. Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a71728",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ac88818",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'missingno'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14028\\1682916150.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#Missing data vizualization libraries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmissingno\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmsno\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mppscore\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'missingno'"
     ]
    }
   ],
   "source": [
    "#Fundamental libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "#Plot libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Missing data vizualization libraries\n",
    "import missingno as msno\n",
    "import ppscore as pps\n",
    "\n",
    "# read data\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d79f798",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c658fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory one step back and save as the root directory\n",
    "root_dir = os.path.normpath(os.getcwd() + os.sep + os.pardir)\n",
    "\n",
    "# Define the location of data directory\n",
    "path = root_dir + '\\\\data\\\\'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae48109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the file name\n",
    "file_path = path + 'ultimate_data_challenge.json'\n",
    "\n",
    "#Read JSON file into a dataframe: df\n",
    "df = pd.read_json(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b53407",
   "metadata": {},
   "source": [
    "## 3. Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05115b3a",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ad4bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_dataframe(df):\n",
    "    print('Describe non-numeric columns:')\n",
    "    display(df.describe(include = ['O', 'bool']).round(2).T)\n",
    "    \n",
    "    print('\\nDescribe numeric columns:')\n",
    "    display(df.describe().round(2).T)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e47847",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing data helper function\n",
    "def count_missing(df):\n",
    "    ''' Count the number of missing values .isnull() in each column well as the percentages \n",
    "    Call pd.concat() to form a single table df with 'count' and '%' columns'''\n",
    "    \n",
    "    print('\\nMissing data stasts')\n",
    "    missing = pd.concat([df.isnull().sum(), 100 * df.isnull().mean()], axis=1)\n",
    "    missing.columns=['count', '%']\n",
    "    missing = missing.loc[missing['count'] > 0]\n",
    "    missing.sort_values(by='count', inplace = True, ascending = False)\n",
    "    \n",
    "    return missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f64627",
   "metadata": {},
   "source": [
    "### Data inspection and exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4822596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check size of the dataframe\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdcde36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Display top 10 rows of the df\n",
    "display(df.head(10).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3396b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7d809f",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab04a2c",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06861ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No further cleaning is required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3bab0e",
   "metadata": {},
   "source": [
    "### Handling of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff21dfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing data stats\n",
    "count_missing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5c95cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop 'phone' columns\n",
    "df.drop('phone', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd536755",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the median value and replace missing values\n",
    "median_1 = df['avg_rating_of_driver'].median()\n",
    "df['avg_rating_of_driver'].fillna(median_1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ec4bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the median value and replace missing values\n",
    "median_2 = df['avg_rating_of_driver'].median()\n",
    "df['avg_rating_by_driver'].fillna(median_2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27994624",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_missing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526f5bf6",
   "metadata": {},
   "source": [
    "### Transformation and formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd6f8c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set datetime formt used in the dataset\n",
    "datetime_format = '%Y-%m-%d'\n",
    "\n",
    "#create a list of datetime columns\n",
    "date_columns = ['signup_date', 'last_trip_date']\n",
    "\n",
    "#Change `date_columns` coluumn data type to `datetime`\n",
    "for column in date_columns:\n",
    "    df[column] = pd.to_datetime(df[column], format=datetime_format, errors=\"raise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a627f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check data type of datetime columns\n",
    "df[date_columns].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2e5d21",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6879fb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace True False for ultimate_black_user with 1 and 0\n",
    "df ['ultimate_black_user'] =  df['ultimate_black_user'].replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db624c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the last date in data\n",
    "last_date = (max(df['last_trip_date']))\n",
    "\n",
    "# Define cut off date as 30 days before that date\n",
    "threshold_date = last_date - pd.Timedelta(days=30)\n",
    "\n",
    "# create the 'active' column based on the 'date' column and the threshold date\n",
    "df['active'] = (df['last_trip_date'] > threshold_date).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a34e6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column to calculate how many days since sign-up\n",
    "df['since_signup_date'] = -1 * (df['signup_date'] - pd.to_datetime(last_date)).dt.days\n",
    "\n",
    "#drop signup date and last_trip_date\n",
    "df.drop('signup_date', axis=1, inplace=True)\n",
    "df.drop('last_trip_date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6537fc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "retention_rate = 100 * df['active'].sum()/len(df)\n",
    "print(f'Driver retention rate is {retention_rate:0.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4fe7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1hat = pd.get_dummies(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbdc79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1hat.head(10).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ad8223",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1458f586",
   "metadata": {},
   "source": [
    "Define Categorical vs numerica features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b620e48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define categrical and numerical data\n",
    "num_columns = ['trips_in_first_30_days', 'avg_rating_of_driver', 'avg_rating_by_driver',\n",
    "             'avg_surge', 'surge_pct', 'weekday_pct',  'avg_dist',  \n",
    "             'since_signup_date']\n",
    "\n",
    "#Seperate categorical data\n",
    "cat_columns = ['city_Astapor', \"city_King's Landing\", 'city_Winterfell',  'ultimate_black_user']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16579bb5",
   "metadata": {},
   "source": [
    "### Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9490a7b7",
   "metadata": {},
   "source": [
    "#### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc423fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a pivot table for categorical columns\n",
    "dfg_cat = pd.DataFrame(df_1hat.groupby('active')[cat_columns].sum()).reset_index()\n",
    "display(dfg_cat)\n",
    "\n",
    "# metlt the pivot table to plotable features\n",
    "dfg_cat_melt = pd.melt(dfg_cat, id_vars = ['active'], var_name='Feature', value_name = 'Count')\n",
    "display(dfg_cat_melt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e582b409",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac03a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the hue for the 'active' column\n",
    "hue_order = [True, False]\n",
    "\n",
    "#Plot the `dfg_melt`\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "sns.barplot(data=dfg_cat_melt, y='Feature', x='Count', hue = 'active', hue_order=hue_order)\n",
    "plt.title('Categorical Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e37fd5",
   "metadata": {},
   "source": [
    "### Numerical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27883ef",
   "metadata": {},
   "source": [
    "#### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932b1bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate active and disactive\n",
    "df_active_num = df_1hat[num_columns].loc[df_1hat['active'] == 1]\n",
    "df_disactive_num = df_1hat[num_columns].loc[~df_1hat['active'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b155c240",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcualte stats \n",
    "#Active \n",
    "df_active_describe= df_active_num.describe().loc[['count', 'mean', 'std']].T\n",
    "df_active_describe['cv'] = df_active_describe['std']/df_active_describe['mean']\n",
    "df_active_describe['active'] = 1\n",
    "\n",
    "#Disactive\n",
    "df_disactive_describe= df_disactive_num.describe().loc[['count', 'mean', 'std']].T\n",
    "df_disactive_describe['cv'] = df_disactive_describe['std']/df_disactive_describe['mean']\n",
    "df_disactive_describe['active'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de09abfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat stat tables\n",
    "df_num_describe = pd.concat([df_active_describe,df_disactive_describe],axis = 0)\n",
    "\n",
    "display(df_num_describe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f141c49",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1039c8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot histogram of all features\n",
    "df_1hat.hist(figsize=(12,12), bins = 12)\n",
    "plt.subplots_adjust(hspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09d2b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the hue for the 'active' column\n",
    "hue_order = [True, False]\n",
    "\n",
    "#Plot the stats\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 5))\n",
    "\n",
    "#plot mean values\n",
    "sns.barplot(data = df_num_describe,\n",
    "            y = df_num_describe.index,\n",
    "            x = 'mean',\n",
    "            hue = 'active',\n",
    "            hue_order = hue_order,\n",
    "            ax=axes[0])\n",
    "axes[0].set_title('Mean Values')\n",
    "\n",
    "#plot cv values\n",
    "sns.barplot(data = df_num_describe,\n",
    "            y = df_num_describe.index,\n",
    "            x = 'cv',\n",
    "            hue = 'active',\n",
    "            hue_order = hue_order,\n",
    "            ax=axes[1])\n",
    "axes[1].set_title('Coefincent of Variance (CV)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4298161",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,9))\n",
    "\n",
    "sns.boxplot(data = df_1hat,\n",
    "            orient = 'h',\n",
    "            width=0.8,\n",
    "            palette='crest',\n",
    "            linewidth= 1,\n",
    "            sym = '')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571ef937",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df_1hat.sample(100)\n",
    "\n",
    "# Set the style of the plots\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "\n",
    "# Set the hue for the 'active' column\n",
    "hue_order = [True, False]\n",
    "\n",
    "# Plot histograms of numerical columns\n",
    "g = sns.pairplot(df_plot, diag_kind=\"kde\", hue='active', vars = num_columns, hue_order=hue_order)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fe333a",
   "metadata": {},
   "source": [
    "### Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba465e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr_matrix (df, round_vals, mask = True):\n",
    "    '''This function plots Correlation matrix'''\n",
    "    \n",
    "    # Compute the correlation matrix\n",
    "    corr = df.corr()\n",
    "        \n",
    "    # Generate a mask for the upper triangle\n",
    "    if mask:\n",
    "        mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "    \n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(25, 12))\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(corr.round(round_vals), mask=mask, cmap='coolwarm', vmin = -1, vmax=1, center=0, annot=True,\n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": .5}).set(title='Pearson Correlation Matrix')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d401324",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Corr matrix\n",
    "plot_corr_matrix(df_1hat, 2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2462eebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pps_matrix(df, round_vals, mask = True):\n",
    "    '''This function gets a df and plot PPS score matrix'''\n",
    "    \n",
    "    # Compute the PPS matrix\n",
    "    matrix = pps.matrix(df)\n",
    "\n",
    "    #Plot PPS\n",
    "    matrix_pps = matrix[['x', 'y', 'ppscore']].pivot(columns='x', index='y', values='ppscore')\n",
    "\n",
    "    # Generate a mask for the upper triangle\n",
    "    if mask:\n",
    "        mask = np.triu(np.ones_like(matrix_pps, dtype=bool))\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(25, 12))\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(matrix_pps.round(round_vals), mask = mask, cmap=\"Blues\", vmin = 0, vmax=1, center=0.5,\n",
    "                square=True, linewidths=.5,annot=True, cbar_kws={\"shrink\": .5}).set(title='PPS Matrix')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f4201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Plot PPS\n",
    "plot_pps_matrix(df=df_1hat, round_vals=2, mask=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a3b79f",
   "metadata": {},
   "source": [
    "## 5. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d629bcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "\n",
    "# check version\n",
    "from pycaret.utils import version\n",
    "version()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c333eca2",
   "metadata": {},
   "source": [
    "### Initialize Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a753d0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_1hat\n",
    "data.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8c9670",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573e405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = setup(data=data,\n",
    "             target = 'active',\n",
    "             session_id=123,\n",
    "             log_experiment=True,\n",
    "             transformation=True,\n",
    "             train_size=0.7,\n",
    "             categorical_features= cat_columns,\n",
    "             log_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe11824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b9932f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c420b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "319b575c",
   "metadata": {},
   "source": [
    "## 6. Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b3b42a",
   "metadata": {},
   "source": [
    "## 7. Communication of Results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
